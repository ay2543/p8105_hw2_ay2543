HW2
================
2022-09-29

# Problem 1

Before we do anything, load the `tidyverse` package.

``` r
library(tidyverse)
```

Now we can get started!

First, load the data.

``` r
# Read data and clean names
transit = read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
                   col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c"))  %>% 
  janitor::clean_names()
  
# Check column names of imported data
colnames(transit)
```

    ##  [1] "division"           "line"               "station_name"      
    ##  [4] "station_latitude"   "station_longitude"  "route1"            
    ##  [7] "route2"             "route3"             "route4"            
    ## [10] "route5"             "route6"             "route7"            
    ## [13] "route8"             "route9"             "route10"           
    ## [16] "route11"            "entrance_type"      "entry"             
    ## [19] "exit_only"          "vending"            "staffing"          
    ## [22] "staff_hours"        "ada"                "ada_notes"         
    ## [25] "free_crossover"     "north_south_street" "east_west_street"  
    ## [28] "corner"             "entrance_latitude"  "entrance_longitude"
    ## [31] "station_location"   "entrance_location"

Next we do some cleaning.

``` r
transit_clean = transit %>% 
 select(line:entry, vending, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

transit_clean is a 1868x19 dataset with the following variables:

-   `line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entrance_type, entry, vending, ada`

However, there are still many separate variables in transit_clean that
could be combined to be tidier.

Here are some other details about the dataset.

``` r
# Number of distinct stations
nrow(distinct(transit_clean, station_name))
```

    ## [1] 356

There are **356** distinct stations.

``` r
# ADA-compliant stations

transit_clean %>% filter(ada == TRUE) %>% nrow()
```

    ## [1] 468

**468** stations are ADA-compliant.

``` r
# Proportion of station entrances/exits without vending that allow entry
transit_clean %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean()
```

    ## [1] 0.3770492

**37.704918%** of station entrances/exits without vending allow entry.

Let’s make transit_clean tidy by reformatting the route number and name
with `pivot_longer`, and then filter by distinct stations that serve the
A train and how many of those are ADA compliant.

``` r
transit_tidy = 
  transit_clean %>% 
  pivot_longer(route1:route11, 
               names_to = "route_number",
               values_to = "route_name") 

transit_tidy %>% 
  filter(route_name == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
transit_tidy %>% 
  filter(route_name == "A", ada == "TRUE") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

**60** distinct stations serve the A train, and **17** distinct stations
serve the A train and are ADA compliant.

# Problem 2

First, load the additional required packages for this problem.

``` r
library(readxl)
```

Now, I can load the Mr. Trash Wheel sheet within the Trash Wheel
Collection Excel file. I specified a range that excludes the figures and
columns containing notes, as well as omitting the final row indicating a
grand total.

After cleaning the variable names with `clean_names`, I renamed the
weight_tons and volume_cubic_yards variables to be shorter. I filtered
away observations that did not include dumpster-specific data with
`filter`, and used `mutate` to round the number of sports balls to the
nearest integer, and add a variable indicating this dataset was from the
Mr. Trash Wheel sheet.

``` r
mrtrash = read_excel("./data/Trash Wheel Collection Data.xlsx", 
                   sheet = "Mr. Trash Wheel", 
                   range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  rename(weight = weight_tons,
                volume = volume_cubic_yards) %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls),
         year = as.double(year),
         sheet = "Mr. Trash Wheel")
```

Then I did the same with the Professor Trash Wheel sheet:

``` r
proftrash = read_excel("./data/Trash Wheel Collection Data.xlsx", 
                   sheet = "Professor Trash Wheel", 
                   range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  rename(weight = weight_tons,
                volume = volume_cubic_yards) %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sheet = "Professor Trash Wheel")
```

Now I can use a `full_join` to combine the datasets into one dataset
called trash.

``` r
trash = full_join(mrtrash, proftrash)
```

The combined data set consists of **641 observations and 15 variables**.
The included variables are *dumpster, month, year, date, weight, volume,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
grocery_bags, chip_bags, sports_balls, homes_powered, sheet*, with the
last variable being an indicator of the original sheet the observation
was taken from.

The total weight of trash collected by Professor Trash Wheel was
**190.12 tons**.

The total number of sports balls collected by Mr. Trash Wheel in 2020
was **856 tons**.

# Problem 3

First, I loaded the pols dataset, then used `separate()` to break up the
mon variable into year, month and day. Then I used `lubridate::month` to
replace the month number with the month name. I then used `pivot_longer`
to create a president variable taking values from prez_dem and prez_gop.
Finally, I removed the day variable with `select`.

``` r
pols = read_csv("./data/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = lubridate::month(as.numeric(month), label = TRUE, abbr = FALSE),
         year = as.double(year)) %>% 
  pivot_longer(c(prez_dem, prez_gop),
               names_to = "president",
               names_prefix = "prez_",
               values_to = "president_value") %>% 
  select(-day)
```

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns. I cleaned
the snp dataset in a similar process as above. Since the date variable
was in a mm/dd/yy format, I first used `lubridate::mdy` to reformat it
into the standard yyyy-mm-dd format, then I separated it into year,
month and day variables with `select`, and changed the month into the
full name and removed the day variable.

``` r
snp = read_csv("./data/snp.csv") %>% 
   mutate(date = lubridate::mdy(date)) %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = lubridate::month(as.numeric(month), label = TRUE, abbr = FALSE),
         year = as.double(year)) %>% 
 select(-day)
```

Next, I tidied the unemployment data by using `pivot_longer` to create a
single month variable instead of having one variable per month, then
cleaned the names with `janitor::clean_names()` to be consistent with
the previous datasets. I changed the month variable from the abbreviated
month names to the full month names by using `factor` with the
abbreviations (month.abb) as the levels and renaming the labels to the
full month names (month.name).

``` r
unemployment = read_csv("./data/unemployment.csv") %>% 
  pivot_longer(Jan:Dec,
               names_to = "month",
               values_to = "unemployment") %>% 
  janitor::clean_names() %>% 
  mutate(month = factor(month, levels = month.abb, labels = month.name, ordered = TRUE),
         year = as.double(year))
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

Finally, I used `left_join` to merge snp into pols, and then
unemployment into the earlier merge.

``` r
merge_df = left_join(pols, snp) %>% 
  left_join(., unemployment)
```

    ## Joining, by = c("year", "month")
    ## Joining, by = c("year", "month")

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

The pols dataset contained **1644** observations and **10** variables.
The included variables were *year, month, gov_gop, sen_gop, rep_gop,
gov_dem, sen_dem, rep_dem, president, president_value*.

The snp dataset contained **787** observations and **3** variables. The
included variables were *year, month, close*.

The unemployment dataset contained **816** observations and **3**
variables. The included variables were *year, month, unemployment*.

The resulting merge_df dataset has a dimension of **1644 observations x
12 variables**. The range of years was 1947, 2015, and the variable
names are *year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem,
rep_dem, president, president_value, close, unemployment*.
